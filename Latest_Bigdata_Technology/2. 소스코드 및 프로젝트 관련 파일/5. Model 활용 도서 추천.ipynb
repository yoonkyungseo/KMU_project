{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "735281f7",
   "metadata": {},
   "source": [
    "# Utilize Word2Vec & FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d6326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "# import chromedriver_autoinstaller\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "# 차트에서 한글 출력을 위한 설정\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "your_os = platform.system()\n",
    "if your_os == 'Linux':\n",
    "    rc('font', family='NanumGothic')\n",
    "elif your_os == 'Windows':\n",
    "    ttf = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=ttf).get_name()\n",
    "    \n",
    "    rc('font', family=font_name)\n",
    "elif your_os == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487378a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common. by import By\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "from konlp.kma.klt2023 import klt2023\n",
    "import nltk\n",
    "import stanza\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03e455",
   "metadata": {},
   "source": [
    "#### 코사인 유사도 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988f9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도 함수\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return (dot_product / (norm_v1 * norm_v2)).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318f207",
   "metadata": {},
   "source": [
    "## 도서 내용으로  도서 추천\n",
    "- 문장을 입력하면 해당 문장과 도서 내용의 유사도를 계산하여 유사도가 높은 도서를 추천해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd1bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_recommend(model_name, dataframe, input_sentence, n):\n",
    "    \n",
    "    # 모델 호출\n",
    "    try:\n",
    "        model = Word2Vec.load(model_name)\n",
    "    except:\n",
    "        model = FastText.load(model_name)\n",
    "    \n",
    "    # 데이터프레임 호출\n",
    "    book = pd.read_csv(dataframe)\n",
    "    \n",
    "    k = klt2023()\n",
    "    \n",
    "    input_nouns = list(set(k.nouns(input_sentence)))\n",
    "    \n",
    "    # 단어의 벡터 합 계산\n",
    "    iv=np.zeros(400)\n",
    "    input_vec =[]\n",
    "    for k in input_nouns:\n",
    "        iv += model.wv.get_vector(k)\n",
    "    \n",
    "    # 책벡터와 유사도 계산\n",
    "    cos_num = []\n",
    "    for i in range(len(book)):\n",
    "        book_vector = [np.float(i) for i in book['책소개_벡터'][i][1:-1].split()]\n",
    "        nn = cosine_similarity(iv, book_vector)\n",
    "        cos_num.append(nn.astype('float'))\n",
    "    \n",
    "    if len(cos_num) == len(book):\n",
    "        cos_dic = dict(zip(zip(book['제목'],book['저자']), cos_num))\n",
    "        similar_sentence = sorted(cos_dic.items(), key=lambda x: x[1], reverse = True)\n",
    "        return similar_sentence[:n]\n",
    "    else:\n",
    "        return len(cos_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109b5332",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('행복을 담아줄게', '나란'), 0.35825759059687917),\n",
       " (('있는 그대로', '김지훈'), 0.3403578870621218),\n",
       " (('보이지 않는 곳에서 애쓰고 있는 너에게', '최대호'), 0.33851055987823103),\n",
       " (('당신과 아침에 싸우면 밤에는 입맞출 겁니다', '유래혁'), 0.3367892482086697),\n",
       " (('엄마의 말 공부 일력 365', '이임숙'), 0.3345570815563324)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_recommend('word2vec_book_wiki.model', 'books_vector_wiki.csv', '마음을 편안하게 해주는 위로의 글', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a260a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('당신이 좋아지면, 밤이 깊어지면', '안희연'), 0.7639079225989486),\n",
       " (('나로서 충분히 괜찮은 사람', '김재식'), 0.7610791092550505),\n",
       " (('당신과 아침에 싸우면 밤에는 입맞출 겁니다', '유래혁'), 0.7595994689581971),\n",
       " (('나는 당신이 행복했으면 좋겠습니다', '박찬위'), 0.7592670581220978),\n",
       " (('그대 늙어가는 것이 아니라 익어가는 것이다', '오평선'), 0.7533357641240881)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_recommend('fasttext_book_wiki.model', 'books_vector_wiki.csv', '마음을 편안하게 해주는 위로의 글', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b051f03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('백만장자 시크릿', '하브 에커'), 0.399624876268301),\n",
       " (('멘탈의 연금술', '보도 섀퍼'), 0.36896506015454933),\n",
       " (('10배의 법칙', '그랜트 카돈'), 0.3657964732238805),\n",
       " (('부의 본능(골드 에디션)', '우석'), 0.36520110889494883),\n",
       " (('Give and Take(기브앤테이크)', '애덤 그랜트'), 0.36266554809804324)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_recommend('word2vec_book_wiki.model', 'books_vector_wiki.csv', '부자로 성공하는 방법', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ccf66a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('경매 권리분석 이렇게 쉬웠어?', '박희철(파이팅팔콘)'), 0.64510457835586),\n",
       " (('장단기 투자의 비밀', '래리 윌리엄스'), 0.6328833359318223),\n",
       " (('백만장자 시크릿', '하브 에커'), 0.6326274139210921),\n",
       " (('10대를 위한 그릿', '매슈사이드'), 0.627665727245654),\n",
       " (('Give and Take(기브앤테이크)', '애덤 그랜트'), 0.6266576024101875)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_recommend('fasttext_book_wiki.model', 'books_vector_wiki.csv', '부자로 성공하는 방법', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334e83f",
   "metadata": {},
   "source": [
    "## 단어들의 조합으로 도서 추천 (기억 속의 책 찾기)\n",
    "- positive word와 negative word를 입력받아 해당 조합에 따른 유사 단어를 추출한 후, 이 단어들의 벡터 합과 가장 높은 유사도의 도서 내용을 갖는 도서를 추천해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75650cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_search(model_name, dataframe):\n",
    "    \n",
    "    # 모델 호출\n",
    "    try:\n",
    "        model = Word2Vec.load(model_name)\n",
    "    except:\n",
    "        model = FastText.load(model_name)\n",
    "    \n",
    "    # 데이터프레임 호출\n",
    "    book = pd.read_csv(dataframe)\n",
    "    book_information = zip(book['제목'],book['저자'], book['카테고리'])\n",
    "    \n",
    "    k = klt2023()\n",
    "    \n",
    "    # positive, negative word 입력\n",
    "    posit = input('positive_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):').split()\n",
    "    negat = input('negative_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):').split()\n",
    "    \n",
    "    # 입력단어에 따른 유사 단어 출력\n",
    "    if (len(posit)>0) and (len(negat)>0):\n",
    "        word = model.wv.most_similar(positive=posit, negative=negat)\n",
    "    elif (len(posit)>0):\n",
    "        word = model.wv.most_similar(positive=posit)\n",
    "    else:\n",
    "        word = model.wv.most_similar(negative=negat)\n",
    "    \n",
    "    # 유사 단어들의 벡터 합\n",
    "    w_vector = np.zeros(400)\n",
    "    for w,c in word:\n",
    "        w_vector += model.wv.get_vector(w)\n",
    "    \n",
    "    # 책벡터와 유사도 계산\n",
    "    cos_num = []\n",
    "    for i in range(len(book)):\n",
    "        book_vector = [np.float(i) for i in book['책소개_벡터'][i][1:-1].split()]\n",
    "        nn = cosine_similarity(w_vector, book_vector)\n",
    "        cos_num.append(nn.astype('float'))\n",
    "    \n",
    "    # dictionary 생성\n",
    "    if len(cos_num) == len(book):\n",
    "        cos_dic = dict(zip(book_information, cos_num))\n",
    "        book_similar = sorted(cos_dic.items(), key=lambda x: x[1], reverse = True)\n",
    "        return book_similar[:1]\n",
    "    else:\n",
    "         return len(cos_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20be77f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):가족 사랑 아이 공부\n",
      "negative_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):전쟁 공주 연애\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key '아이' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbook_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword2vec_book_wiki.model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooks_vector_wiki.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mbook_search\u001b[1;34m(model_name, dataframe)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 입력단어에 따른 유사 단어 출력\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(posit)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(negat)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 21\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(posit)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     23\u001b[0m     word \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39mposit)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:773\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    771\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m key)\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 773\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key):\n\u001b[0;32m    775\u001b[0m         all_keys\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:438\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 438\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:412\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key '아이' not present\""
     ]
    }
   ],
   "source": [
    "# word2vec은 학습 데이터에 없는 단어 벡터는 만들어 내지 못하는 단점이 있기 때문에\n",
    "# 해당 예시에서는 '아이'라는 단어가 없어 오류가 난 것을 볼 수 있음\n",
    "book_search('word2vec_book_wiki.model', 'books_vector_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9dd5e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):모험 전쟁 성공\n",
      "negative_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):공주 연애\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('이미 시작된 전쟁', '이철', '정치/사회'), 0.27360490246192454)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_search('word2vec_book_wiki.model', 'books_vector_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba20e7f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):모험 전쟁 성공\n",
      "negative_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):공주 연애\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('로마인 이야기 2: 한니발 전쟁', '시오노 나나미', '역사/문화'), 0.5823006581838892)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_search('fasttext_book_wiki.model', 'books_vector_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ee6cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):마법 성 판타지\n",
      "negative_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('해리 포터 시리즈 1~4권 세트(해리포터 20주년 개정판)', 'J. K. 롤링', '소설'), 0.3743759220949477)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_search('word2vec_book_wiki.model', 'books_vector_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5170163a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):마법 성 판타지\n",
      "negative_word (여러 단어를 쓸 경우, 띄어쓰기로 구분해주세요.):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('해리 포터 시리즈 1~4권 세트(해리포터 20주년 개정판)', 'J. K. 롤링', '소설'), 0.6568774500743274)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_search('fasttext_book_wiki.model', 'books_vector_wiki.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5e7be",
   "metadata": {},
   "source": [
    "## 입력한 단어와 가장 유사한 카테고리의 도서 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a9ab6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestseller(model_name, dataframe, word1, n):\n",
    "    \n",
    "    # 모델 호출\n",
    "    try:\n",
    "        model = Word2Vec.load(model_name)\n",
    "    except:\n",
    "        model = FastText.load(model_name)\n",
    "    \n",
    "    # 데이터프레임 호출\n",
    "    book = pd.read_csv(dataframe)\n",
    "    \n",
    "    k = klt2023()\n",
    "    \n",
    "    # 입력 단어와 카테고리 유사도 계산\n",
    "    categ=[i.split('/') for i in book['카테고리']]\n",
    "    category = list(set(itertools.chain(*categ)))\n",
    "    simil_num=0\n",
    "    for i in category:\n",
    "        simil = model.wv.similarity(u'{}'.format(word1), u'{}'.format(i))\n",
    "        if simil > simil_num:\n",
    "            simil_num = simil\n",
    "            ct = i\n",
    "    \n",
    "    # 해당 카테고리에 해당하는 book 목록으로 재정의\n",
    "    book = book[book['카테고리'].apply(lambda x : ct in x)].reset_index(drop=True)\n",
    "    book_information = zip(book['제목'],book['저자'])\n",
    "    \n",
    "    # 책소개 벡터와 유사도 계산\n",
    "    cos_num = []\n",
    "    word_vec = model.wv.get_vector(word1)\n",
    "    for i in range(len(book)):\n",
    "        book_vector = [np.float(i) for i in book['책소개_벡터'][i][1:-1].split()]\n",
    "        nn = cosine_similarity(word_vec, book_vector)\n",
    "        cos_num.append(nn.astype('float'))\n",
    "    \n",
    "    # dictionary 생성\n",
    "    if len(cos_num) == len(book):\n",
    "        cos_dic = dict(zip(book_information, cos_num))\n",
    "        book_similar = sorted(cos_dic.items(), key=lambda x: x[1], reverse = True)\n",
    "        return simil, ct, book_similar[:n]\n",
    "    else:\n",
    "        return len(cos_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd860529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04292066,\n",
       " '대중문화',\n",
       " [(('SAVE THE CAT!: 흥행하는 영화 시나리오의 8가지 법칙', '블레이크 스나이더'), 0.44993079561155186),\n",
       "  (('우리는 왜 임영웅을 사랑하는가', '조위'), 0.34890712733005674),\n",
       "  (('시나리오 어떻게 쓸 것인가 세트', '로버트 맥키'), 0.343034047968187),\n",
       "  (('데이비드 호크니', '마르코 리빙스턴'), 0.327195837798465),\n",
       "  (('연기하지 않는 연기', '해럴드 거스킨'), 0.31482199930558946)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestseller('fasttext_book_wiki.model', 'books_vector_wiki.csv','성공',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "632fd808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1325179,\n",
       " '소설',\n",
       " [(('해리 포터 시리즈 1~4권 세트(해리포터 20주년 개정판)', 'J. K. 롤링'), 0.6852860696465063),\n",
       "  (('해리 포터와 마법사의 돌 1(해리포터 20주년 개정판)', 'J. K. 롤링'), 0.6755744803449041),\n",
       "  (('해리 포터와 마법사의 돌 2(해리포터 20주년 개정판)', 'J. K. 롤링'), 0.6755744803449041),\n",
       "  (('해리 포터와 마법사의 돌(해리포터 20주년 개정판)', 'J. K. 롤링'), 0.6755744803449041),\n",
       "  (('해리 포터와 아즈카반의 죄수 1(해리포터 20주년 개정판)', 'J. K. 롤링'), 0.665523252850332)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestseller('fasttext_book_wiki.model', 'books_vector_wiki.csv','모험',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c336708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "86a31a77840389aa372d7b862bafbdd9454b644d3f50255236297305dde606c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
